{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    " \n",
    "class CentroidTracker():\n",
    "    def __init__(self, maxDisappeared=100):\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "        \n",
    "    def register(self, centroid):\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "        \n",
    "    def deregister(self, objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        \n",
    "    def update(self, rects):\n",
    "        if len(rects) == 0:\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "            return self.objects\n",
    "        \n",
    "        # initialize an array of input centroids for the current frame\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "\n",
    "        # loop over the bounding box rectangles\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            # use the bounding box coordinates to derive the centroid\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "            \n",
    "        # if we are currently not tracking any objects take the input\n",
    "        # centroids and register each of them\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "        \n",
    "        else:\n",
    "            # grab the set of object IDs and corresponding centroids\n",
    "            objectIDs = list(self.objects.keys())\n",
    "\n",
    "            objectCentroids = list(self.objects.values())\n",
    "            \n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "            for (row, col) in zip(rows, cols):\n",
    "            \n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.disappeared[objectID] = 0\n",
    " \n",
    "                # indicate that we have examined each of the row and\n",
    "                # column indexes, respectively\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "                \n",
    "            # compute both the row and column index we have NOT yet\n",
    "            # examined\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "            \n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                # loop over the unused row indexes\n",
    "                for row in unusedRows:\n",
    "                    # grab the object ID for the corresponding row\n",
    "                    # index and increment the disappeared counter\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    " \n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "                        \n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    " \n",
    "        # return the set of trackable objects\n",
    "        return self.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82421549, 0.32755369, 0.33198071],\n",
       "       [0.72642889, 0.72506609, 0.17058938]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "objectCentroids = np.random.uniform(size=(2, 2))\n",
    "centroids = np.random.uniform(size=(3, 2))\n",
    "D = dist.cdist(objectCentroids, centroids) # Euclidean distance between the pairs\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch, torchvision\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "#cfg.DATASETS.TRAIN = (\"straindata\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 900    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "cfg.MODEL.WEIGHTS = \"C:\\\\Users\\\\siraj\\\\UB_prototypes\\\\Fish Mortality\\\\fish_detectionv4.pth\"  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9   # set a custom testing threshold\n",
    "cfg.MODEL.DEVICE = 'cpu'\n",
    "# cfg.DATASETS.TEST=(\"straindata49\",)\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='traindata1',\n",
       "          json_file='C:\\\\Users\\\\siraj\\\\UB_prototypes\\\\Biomass_Estimation_prod\\\\detectFish_v3\\\\trainval.json',\n",
       "          image_root='C:\\\\Users\\\\siraj\\\\UB_prototypes\\\\Biomass_Estimation_prod\\\\detectFish_v3\\\\images',\n",
       "          evaluator_type='coco',\n",
       "          thing_classes=['Fish'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detectron2.utils.visualizer4 import ColorMode\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"traindata1\",{},\"C:\\\\Users\\\\siraj\\\\UB_prototypes\\\\Biomass_Estimation_prod\\\\detectFish_v3\\\\trainval.json\",\"C:\\\\Users\\\\siraj\\\\UB_prototypes\\\\Biomass_Estimation_prod\\\\detectFish_v3\\\\images\")\n",
    "sample_metaadata=MetadataCatalog.get(\"traindata1\") \n",
    "MetadataCatalog.get(\"traindata1\").set(thing_classes=[\"Fish\"])\n",
    "#sample_metaadata=MetadataCatalog.get(\"traindata1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siraj\\anaconda3\\envs\\detectron2\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "C:\\Users\\siraj\\anaconda3\\envs\\detectron2\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85  0.325 0.098]\n",
      "[1.    0.667 0.5  ]\n",
      "[1.    0.667 1.   ]\n",
      "[1.    0.333 0.   ]\n",
      "[0.333 0.667 0.5  ]\n",
      "[0.    0.333 0.   ]\n",
      "[0.85  0.325 0.098]\n",
      "[0. 1. 0.]\n",
      "Length8\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n",
      "[0. 1. 1.]\n",
      "[0.    0.167 0.   ]\n",
      "[0.667 0.333 0.5  ]\n",
      "[1. 0. 0.]\n",
      "[0.667 1.    0.   ]\n",
      "[1.    0.333 0.   ]\n",
      "[0.667 0.667 1.   ]\n",
      "Length7\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "2\n",
      "[0.667 0.    1.   ]\n",
      "[0.    0.667 0.   ]\n",
      "[0.667 0.    1.   ]\n",
      "[0.    0.667 0.   ]\n",
      "[0.    0.333 0.   ]\n",
      "[0.    0.667 0.   ]\n",
      "[0.5 0.  0. ]\n",
      "[1. 0. 1.]\n",
      "Length8\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "3\n",
      "[0.333 1.    0.   ]\n",
      "[0.857 0.857 0.857]\n",
      "[0.929 0.694 0.125]\n",
      "[0. 1. 0.]\n",
      "[0.494 0.184 0.556]\n",
      "[1.  1.  0.5]\n",
      "[0.667 1.    0.   ]\n",
      "[1. 0. 1.]\n",
      "[0.635 0.078 0.184]\n",
      "Length9\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "4\n",
      "[0.6 0.6 0.6]\n",
      "[0. 0. 1.]\n",
      "[0.    0.333 0.   ]\n",
      "[0.85  0.325 0.098]\n",
      "[0.    0.333 0.   ]\n",
      "[1.    0.667 1.   ]\n",
      "[0. 0. 0.]\n",
      "Length7\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "5\n",
      "[0.667 0.    1.   ]\n",
      "[0.3 0.3 0.3]\n",
      "[1.  0.  0.5]\n",
      "[0.333 0.333 1.   ]\n",
      "[0.667 1.    1.   ]\n",
      "[0.494 0.184 0.556]\n",
      "[0.667 1.    0.5  ]\n",
      "Length7\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "6\n",
      "[0.494 0.184 0.556]\n",
      "[0.85  0.325 0.098]\n",
      "[0.301 0.745 0.933]\n",
      "[0.333 1.    0.   ]\n",
      "[0.333 0.    0.   ]\n",
      "[0.333 0.333 1.   ]\n",
      "[0.333 0.    0.   ]\n",
      "[0.    0.833 0.   ]\n",
      "Length8\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "7\n",
      "[0.667 0.    1.   ]\n",
      "[0.    0.667 0.   ]\n",
      "[1. 1. 1.]\n",
      "[0.667 0.667 0.5  ]\n",
      "[0.667 0.333 1.   ]\n",
      "[0. 0. 1.]\n",
      "[0.143 0.143 0.143]\n",
      "[0.    0.667 0.   ]\n",
      "Length8\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "8\n",
      "[0.333 0.333 0.5  ]\n",
      "[1.    0.667 1.   ]\n",
      "[0.    0.667 0.5  ]\n",
      "[1. 1. 0.]\n",
      "[0.333 0.667 1.   ]\n",
      "[0.    0.333 0.   ]\n",
      "[0.    0.333 1.   ]\n",
      "[0.    0.667 1.   ]\n",
      "[0.667 0.    1.   ]\n",
      "[0.    0.    0.167]\n",
      "Length10\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "9\n",
      "[0.    0.833 0.   ]\n",
      "[0.6 0.6 0.6]\n",
      "[0.    0.447 0.741]\n",
      "[0. 0. 0.]\n",
      "[1.  0.5 0. ]\n",
      "[0.3 0.3 0.3]\n",
      "Length6\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "10\n",
      "[0.635 0.078 0.184]\n",
      "[0.667 1.    0.5  ]\n",
      "[0.667 0.333 0.5  ]\n",
      "[0.3 0.3 0.3]\n",
      "[0.333 0.    0.5  ]\n",
      "[0.667 1.    0.5  ]\n",
      "[0.    0.667 1.   ]\n",
      "[0.466 0.674 0.188]\n",
      "Length8\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "11\n",
      "[1.    0.667 0.   ]\n",
      "[0.857 0.857 0.857]\n",
      "[0.749 0.749 0.   ]\n",
      "[0.667 0.667 0.5  ]\n",
      "[0.667 0.333 0.5  ]\n",
      "[0.143 0.143 0.143]\n",
      "[0.667 0.333 1.   ]\n",
      "Length7\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "12\n",
      "[0.333 0.333 1.   ]\n",
      "[0.667 1.    0.5  ]\n",
      "[0.    0.667 0.   ]\n",
      "[0.667 0.    1.   ]\n",
      "[1.    0.333 0.5  ]\n",
      "[0.    0.    0.167]\n",
      "[0.929 0.694 0.125]\n",
      "Length7\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "13\n",
      "[1. 0. 1.]\n",
      "[0.  1.  0.5]\n",
      "[0.667 0.    1.   ]\n",
      "[0.466 0.674 0.188]\n",
      "[0.6 0.6 0.6]\n",
      "[0.    0.447 0.741]\n",
      "[0. 0. 1.]\n",
      "[0. 1. 1.]\n",
      "[0.    0.833 0.   ]\n",
      "Length9\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "14\n",
      "[1.    0.667 0.   ]\n",
      "[0.494 0.184 0.556]\n",
      "[0. 0. 0.]\n",
      "[0.667 0.    1.   ]\n",
      "[0. 1. 0.]\n",
      "[1.    0.333 1.   ]\n",
      "[0.333 0.    1.   ]\n",
      "[0.    0.167 0.   ]\n",
      "[0.667 0.    0.5  ]\n",
      "[0.333 0.333 0.5  ]\n",
      "[1.  0.  0.5]\n",
      "Length11\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "15\n",
      "[0.833 0.    0.   ]\n",
      "[0.    0.    0.333]\n",
      "[0.333 0.667 1.   ]\n",
      "[0.    0.667 0.   ]\n",
      "[0.333 0.    0.5  ]\n",
      "[0.333 0.333 1.   ]\n",
      "[0.333 0.    0.5  ]\n",
      "[0.    0.667 0.   ]\n",
      "[0. 1. 1.]\n",
      "[0.333 0.667 0.5  ]\n",
      "[0.333 0.    0.5  ]\n",
      "[0.301 0.745 0.933]\n",
      "Length12\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "16\n",
      "[0.  1.  0.5]\n",
      "[0.929 0.694 0.125]\n",
      "[0. 0. 1.]\n",
      "[0.    0.447 0.741]\n",
      "[1. 0. 1.]\n",
      "[0.    0.667 0.   ]\n",
      "[0.    0.667 0.   ]\n",
      "[0.    0.667 0.   ]\n",
      "[0.  1.  0.5]\n",
      "[0.6 0.6 0.6]\n",
      "[1.    0.333 0.5  ]\n",
      "[0.143 0.143 0.143]\n",
      "[0.333 0.333 1.   ]\n",
      "Length13\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "17\n",
      "[0.    0.167 0.   ]\n",
      "[1.  1.  0.5]\n",
      "[0.85  0.325 0.098]\n",
      "[1. 0. 0.]\n",
      "[1.    0.333 1.   ]\n",
      "[1. 1. 0.]\n",
      "[1.    0.333 1.   ]\n",
      "[0.667 0.    0.5  ]\n",
      "[0.929 0.694 0.125]\n",
      "[0.    0.667 0.   ]\n",
      "[0.749 0.749 0.   ]\n",
      "Length11\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "18\n",
      "[0.667 0.333 0.   ]\n",
      "[0.    0.167 0.   ]\n",
      "[1.    0.667 1.   ]\n",
      "[0.333 0.    0.   ]\n",
      "[0.85  0.325 0.098]\n",
      "[0.    0.447 0.741]\n",
      "[0.333 0.333 1.   ]\n",
      "[0.667 0.    0.   ]\n",
      "[0.85  0.325 0.098]\n",
      "[0.85  0.325 0.098]\n",
      "Length10\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "19\n",
      "[1.    0.667 0.5  ]\n",
      "[0.    0.    0.833]\n",
      "[0.667 0.    0.5  ]\n",
      "[0.5 0.  0. ]\n",
      "[0. 0. 1.]\n",
      "[0.333 0.667 0.   ]\n",
      "[0. 0. 1.]\n",
      "[0.667 0.    0.   ]\n",
      "[0.667 0.    0.5  ]\n",
      "[1. 1. 0.]\n",
      "[0.    0.    0.667]\n",
      "Length11\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "20\n",
      "[0.667 0.333 0.   ]\n",
      "[0.    0.167 0.   ]\n",
      "[0.667 0.667 0.   ]\n",
      "[0.    0.167 0.   ]\n",
      "[0.857 0.857 0.857]\n",
      "[1.  0.5 0. ]\n",
      "[0.929 0.694 0.125]\n",
      "[0.333 0.333 0.   ]\n",
      "[0. 0. 1.]\n",
      "[1.  0.  0.5]\n",
      "Length10\n",
      "My classes names\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from PIL import Image\n",
    "# initialize our centroid tracker and frame dimensions\n",
    "ct = CentroidTracker()\n",
    "(H, W) = (None, None)\n",
    " \n",
    "video = cv2.VideoCapture(\"C:\\\\Users\\\\siraj\\\\office_work_UB\\\\Testing.mp4\")\n",
    "\n",
    "if (video.isOpened() == False):\n",
    "    print(\"Error reading video file\")\n",
    "frame_width = int(video.get(3))\n",
    "frame_height = int(video.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "def predict_frame(frame):\n",
    "    frame2 = frame.copy()\n",
    "    #frame2=cv2.resize(frame2,size)\n",
    "    outputs = predictor(frame2)\n",
    "    v = Visualizer(frame2[:, :, ::-1],\n",
    "                   metadata=sample_metaadata, \n",
    "                   scale=0.8, \n",
    "        instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "        )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    outputnump=outputs[\"instances\"].pred_boxes.tensor.numpy()\n",
    "    my_class_names=(outputs[\"instances\"].pred_classes.tolist())\n",
    "    length=len(outputnump)\n",
    "    print(\"Length\"+str(length))\n",
    "    print(\"My classes names\")\n",
    "    print(my_class_names)\n",
    "    Person=0\n",
    "    for j in range(len(my_class_names)):\n",
    "        if(my_class_names[j]==0):\n",
    "            Person+=1\n",
    "\n",
    "    for i in range(len(outputnump)):\n",
    "        box=outputnump[i]\n",
    "        rects.append(box.astype(\"int\"))\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "                    (255, 0, 0), 2)    \n",
    "\n",
    "    myresult=out.get_image()[:, :, ::-1]\n",
    "    #frame2=cv2.resize(myresult,size)\n",
    "    #print( \"myresult\", frame2.shape[1], frame2.shape[0])\n",
    "    #cv2.putText(frame2, \"Total= \"+str(Person), (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "    #cv2.putText(frame2, \"Skeleton = \"+str(skull), (30, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)\n",
    "    #cv2.putText(frame2, \"Kingfish = \"+str(kFish), (30, 140), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 0, 0), 2)\n",
    "    #cv2.imwrite(\"yellow_bucket2//frame\"+str(abcd)+\".jpg\",frame2)\n",
    "    return frame2,rects,length\n",
    "\n",
    "result = cv2.VideoWriter('fish_tracking4.mp4',\n",
    "                         cv2.VideoWriter_fourcc(*'DIVX'),\n",
    "                         30, size)\n",
    "count = 0\n",
    "total_dic={}\n",
    "\n",
    "while(True) and count<=20:\n",
    "    ret, frame = video.read()\n",
    "    if ret == True:\n",
    "        rects = []  \n",
    "        print(count)\n",
    "        #frame,rects,length = predict_frame(frame)\n",
    "        \n",
    "        frame,rects,length = predict_frame(frame)\n",
    "        objects = ct.update(rects)\n",
    "        # loop over the tracked objects\n",
    "        # loop over the tracked objects\n",
    "        for (objectID, centroid) in objects.items():\n",
    "            # draw both the ID of the object and the centroid of the\n",
    "            # object on the output frame\n",
    "            #print(\"Rectsss\", rects[objectID])\n",
    "        \n",
    "            #frame = cv2.rectangle(frame, (x1_text,y1_text), (x2_text,y2_text), (0,0,255), 2)\n",
    "            text = \"ID {}\".format(objectID)\n",
    "            cv2.putText(frame, text, (centroid[0] - 10, centroid[1] - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0 , 255), 2)\n",
    "            cv2.circle(frame, (centroid[0], centroid[1]), 2, (0, 255, 0), -1)\n",
    "            # show the output frame\n",
    "                          \n",
    "        result.write(frame)\n",
    "        Person=0\n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "            break\n",
    "        count += 1\n",
    "    else:\n",
    "        break         \n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n",
    "result.release() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
